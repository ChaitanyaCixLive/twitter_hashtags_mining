# results<-rbind(results,new.row)
#results[b,c]<-cooc_number
}
}
library(rmongodb)
# query MongoDB
mongo = mongo.create()
db.coll <- 'streamingAPI.test'
cursor <- mongo.find(mongo, db.coll, query = '{}', fields = '{"_id":true,"entities.hashtags.text":true}')
# build data frame
coll <- mongo.cursor.to.list(cursor)
tweet_id <- c()
hashtag<-c()
final_df <- data.frame(tweet_id, hashtag)
for(d in seq_along(coll)){
doc<-coll[[d]]
tweet_id <- c()
hashtag<-c()
for(i in seq_along(doc$entities$hashtags)){
tweet_id <- append(tweet_id, c(doc$`_id`))
hashtag <- append(hashtag, c(doc$entities$hashtags[i][[1]]$text))
}
temp_df <- data.frame(tweet_id, hashtag)
final_df <- rbind(final_df, temp_df)
temp_df <- NULL
}
View(final_df)
hash_tweet_occurrence <- xtabs(~tweet_id + hashtag, data=final_df)
tw_hash <- as.matrix(hash_tweet_occurrence)
results<-matrix(0,nrow=dim(tw_hash)[2],ncol=dim(tw_hash)[2])
options(warnings=-1)
for(a in 1:dim(tw_hash)[1]){
#pull the first element from the vector of treatments // take the first hash (tweet)
tw.temp<-tw_hash[a,]
# #subset the dataset for those treatments // keep only the tweets (#) rows (columns) where the hash (tweet) appear rep[a]=1
# temp<-subset(tw_hash, rep(tw_hash)==tw.temp)
#in this case the community data started at column 6, so the loop for co-occurrence has to start at that point
for(b in 1:(length(tw.temp)-1)){
#every species will be compared to every other species, so there has to be another loop that iterates down the rest of the columns
for(c in (b+1):(length(tw.temp))){
# for (d in 1:dim(temp)[1]) {
#
#   cooc_true <- sum(temp[d])
#   cooc_number <- 0
#
#   if(cooc_true >=1){
#
#       cooc_number <- cooc_number + 1
# }
if(tw.temp[b]+tw.temp[c]>1){
results[b,c]<-results[b,c]+1
results[c,b]<-results[c,b]+1
}
}
# #summing the abundances of species of the columns that will be compared
# species1.ab<-sum(temp[,b])
# species2.ab<-sum(temp[,c])
#
# #if the column is all 0's no co-occurrence will be performed
# if(species1.ab >1 & species2.ab >1){
#   # test<-cor.test(temp[,b],temp[,c],method="spearman",na.action=na.rm)
#   # rho<-test$estimate
#   # p.value<-test$p.value
#
# }
#
# if(species1.ab <=1 | species2.ab <= 1){
#   rho<-0
#   p.value<-1
# }
# trts = treatment-test
# new.row<-c(cooc_number,colnames(temp)[b],colnames(temp)[c]) # ,rho,p.value,species1.ab,species2.ab)
# results<-rbind(results,new.row)
#results[b,c]<-cooc_number
}
}
head(results)
View(results)
View(adj_mx)
View(adj_mx)
levels(final_df$hashtag)
library(igraph)
install.packages("igraph")
library(igraph)
nodeNames <- levels(final_df$hashtag)
dimnames(adj_mx) <- list(nodeNames, nodeNames)
dimnames(adj_mx) <- list(nodeNames-1, nodeNames-1)
as_adj_mx <- as_adjacency_matrix(adj_mx, sparse = TRUE)
g <- graph_from_adjacency_matrix(as_adj_mx)
g <- graph_from_adjacency_matrix(results)
plot(g)
nodeNames <- levels(final_df$hashtag)
dimnames(results) <- list(nodeNames-1, nodeNames-1)
nodeNames <- levels(final_df$hashtag)
dimnames(results) <- list(nodeNames, nodeNames)
as_adj_mx <- as_adjacency_matrix(results, sparse = TRUE)
g <- graph_from_adjacency_matrix(results)
as_adj_mx <- as_adjacency_matrix(g, sparse = TRUE)
plot(g)
summary(as_adj_mx)
as_adj_mx
head(as_adj_mx)
library(rmongodb)
# query MongoDB
mongo = mongo.create()
db.coll <- 'streamingAPI.test2'
cursor <- mongo.find(mongo, db.coll, query = '{}', fields = '{"_id":true,"entities.hashtags.text":true}')
# build data frame
coll <- mongo.cursor.to.list(cursor)
tweet_id <- c()
hashtag<-c()
final_df <- data.frame(tweet_id, hashtag)
for(d in seq_along(coll)){
doc<-coll[[d]]
tweet_id <- c()
hashtag<-c()
for(i in seq_along(doc$entities$hashtags)){
tweet_id <- append(tweet_id, c(doc$`_id`))
hashtag <- append(hashtag, c(doc$entities$hashtags[i][[1]]$text))
}
temp_df <- data.frame(tweet_id, hashtag)
final_df <- rbind(final_df, temp_df)
temp_df <- NULL
}
hash_tweet_occurrence <- xtabs(~tweet_id + hashtag, data=final_df)
tw_hash <- as.matrix(hash_tweet_occurrence)
results<-matrix(0,nrow=dim(tw_hash)[2],ncol=dim(tw_hash)[2])
options(warnings=-1)
for(a in 1:dim(tw_hash)[1]){
#pull the first element from the vector of treatments // take the first hash (tweet)
tw.temp<-tw_hash[a,]
# #subset the dataset for those treatments // keep only the tweets (#) rows (columns) where the hash (tweet) appear rep[a]=1
# temp<-subset(tw_hash, rep(tw_hash)==tw.temp)
#in this case the community data started at column 6, so the loop for co-occurrence has to start at that point
for(b in 1:(length(tw.temp)-1)){
#every species will be compared to every other species, so there has to be another loop that iterates down the rest of the columns
for(c in (b+1):(length(tw.temp))){
# for (d in 1:dim(temp)[1]) {
#
#   cooc_true <- sum(temp[d])
#   cooc_number <- 0
#
#   if(cooc_true >=1){
#
#       cooc_number <- cooc_number + 1
# }
if(tw.temp[b]+tw.temp[c]>1){
results[b,c]<-results[b,c]+1
results[c,b]<-results[c,b]+1
}
}
# #summing the abundances of species of the columns that will be compared
# species1.ab<-sum(temp[,b])
# species2.ab<-sum(temp[,c])
#
# #if the column is all 0's no co-occurrence will be performed
# if(species1.ab >1 & species2.ab >1){
#   # test<-cor.test(temp[,b],temp[,c],method="spearman",na.action=na.rm)
#   # rho<-test$estimate
#   # p.value<-test$p.value
#
# }
#
# if(species1.ab <=1 | species2.ab <= 1){
#   rho<-0
#   p.value<-1
# }
# trts = treatment-test
# new.row<-c(cooc_number,colnames(temp)[b],colnames(temp)[c]) # ,rho,p.value,species1.ab,species2.ab)
# results<-rbind(results,new.row)
#results[b,c]<-cooc_number
}
}
# plot network
library(igraph)
nodeNames <- levels(final_df$hashtag)
dimnames(results) <- list(nodeNames, nodeNames)
as_adj_mx <- as_adjacency_matrix(g, sparse = TRUE)
g <- graph_from_adjacency_matrix(results)
plot(g)
library(igraph)
nodeNames <- levels(final_df$hashtag)
dimnames(results) <- list(nodeNames, nodeNames)
as_adj_mx <- as_adjacency_matrix(g, sparse = TRUE)
g <- graph_from_adjacency_matrix(results, mode = "upper")
plot(g)
g <- graph_from_adjacency_matrix(results, mode = "upper")
plot(g)
library(rmongodb)
# query MongoDB
mongo = mongo.create()
db.coll <- 'streamingAPI.test'
cursor <- mongo.find(mongo, db.coll, query = '{}', fields = '{"_id":true,"entities.hashtags.text":true}')
# build data frame
coll <- mongo.cursor.to.list(cursor)
tweet_id <- c()
hashtag<-c()
final_df <- data.frame(tweet_id, hashtag)
for(d in seq_along(coll)){
doc<-coll[[d]]
tweet_id <- c()
hashtag<-c()
for(i in seq_along(doc$entities$hashtags)){
tweet_id <- append(tweet_id, c(doc$`_id`))
hashtag <- append(hashtag, c(doc$entities$hashtags[i][[1]]$text))
}
temp_df <- data.frame(tweet_id, hashtag)
final_df <- rbind(final_df, temp_df)
temp_df <- NULL
}
hash_tweet_occurrence <- xtabs(~tweet_id + hashtag, data=final_df)
tw_hash <- as.matrix(hash_tweet_occurrence)
results<-matrix(0,nrow=dim(tw_hash)[2],ncol=dim(tw_hash)[2])
options(warnings=-1)
for(a in 1:dim(tw_hash)[1]){
#pull the first element from the vector of treatments // take the first hash (tweet)
tw.temp<-tw_hash[a,]
# #subset the dataset for those treatments // keep only the tweets (#) rows (columns) where the hash (tweet) appear rep[a]=1
# temp<-subset(tw_hash, rep(tw_hash)==tw.temp)
#in this case the community data started at column 6, so the loop for co-occurrence has to start at that point
for(b in 1:(length(tw.temp)-1)){
#every species will be compared to every other species, so there has to be another loop that iterates down the rest of the columns
for(c in (b+1):(length(tw.temp))){
# for (d in 1:dim(temp)[1]) {
#
#   cooc_true <- sum(temp[d])
#   cooc_number <- 0
#
#   if(cooc_true >=1){
#
#       cooc_number <- cooc_number + 1
# }
if(tw.temp[b]+tw.temp[c]>1){
results[b,c]<-results[b,c]+1
results[c,b]<-results[c,b]+1
}
}
# #summing the abundances of species of the columns that will be compared
# species1.ab<-sum(temp[,b])
# species2.ab<-sum(temp[,c])
#
# #if the column is all 0's no co-occurrence will be performed
# if(species1.ab >1 & species2.ab >1){
#   # test<-cor.test(temp[,b],temp[,c],method="spearman",na.action=na.rm)
#   # rho<-test$estimate
#   # p.value<-test$p.value
#
# }
#
# if(species1.ab <=1 | species2.ab <= 1){
#   rho<-0
#   p.value<-1
# }
# trts = treatment-test
# new.row<-c(cooc_number,colnames(temp)[b],colnames(temp)[c]) # ,rho,p.value,species1.ab,species2.ab)
# results<-rbind(results,new.row)
#results[b,c]<-cooc_number
}
}
# plot network
library(igraph)
nodeNames <- levels(final_df$hashtag)
dimnames(results) <- list(nodeNames, nodeNames)
as_adj_mx <- as_adjacency_matrix(g, sparse = TRUE)
g <- graph_from_adjacency_matrix(results, mode = "undirected")
plot(g)
library(rmongodb)
# query MongoDB
mongo = mongo.create()
db.coll <- 'streamingAPI.top_occurrences0'
cursor <- mongo.find(mongo, db.coll, query = '{}', fields = '{"_id":true,"entities.hashtags.text":true}')
# build data frame
coll <- mongo.cursor.to.list(cursor)
tweet_id <- c()
hashtag<-c()
final_df <- data.frame(tweet_id, hashtag)
for(d in seq_along(coll)){
doc<-coll[[d]]
tweet_id <- c()
hashtag<-c()
for(i in seq_along(doc$entities$hashtags)){
tweet_id <- append(tweet_id, c(doc$`_id`))
hashtag <- append(hashtag, c(doc$entities$hashtags[i][[1]]$text))
}
temp_df <- data.frame(tweet_id, hashtag)
final_df <- rbind(final_df, temp_df)
temp_df <- NULL
}
g <- graph_from_adjacency_matrix(results, mode = "undirected")
layout_nicely(g, dim = 2)
plot(g)
library(rmongodb)
# query MongoDB
mongo = mongo.create()
db.coll <- 'streamingAPI.test2'
cursor <- mongo.find(mongo, db.coll, query = '{}', fields = '{"_id":true,"entities.hashtags.text":true}')
# build data frame
coll <- mongo.cursor.to.list(cursor)
tweet_id <- c()
hashtag<-c()
final_df <- data.frame(tweet_id, hashtag)
for(d in seq_along(coll)){
doc<-coll[[d]]
tweet_id <- c()
hashtag<-c()
for(i in seq_along(doc$entities$hashtags)){
tweet_id <- append(tweet_id, c(doc$`_id`))
hashtag <- append(hashtag, c(doc$entities$hashtags[i][[1]]$text))
}
temp_df <- data.frame(tweet_id, hashtag)
final_df <- rbind(final_df, temp_df)
temp_df <- NULL
}
# build list
coll <- mongo.cursor.to.list(cursor)
tweet_id <- c()
hashtags<-c()
id_list <- list(tweet_id, hashtags)
for(d in seq_along(coll)){
doc<-coll[[d]]
tweet_id <- c(doc$`_id`)
hashtags<- c()
for(i in seq_along(doc$entities$hashtags)){
hashtags <- append(hashtags, c(doc$entities$hashtags[i][[1]]$text))
}
temp_list <- list(tweet_id=tweet_id, hashtags=hashtags)
id_list[[d]] <- temp_list
temp_list <-NULL
}
hash_tweet_occurrence <- xtabs(~tweet_id + hashtag, data=final_df)
tw_hash <- as.matrix(hash_tweet_occurrence)
results<-matrix(0,nrow=dim(tw_hash)[2],ncol=dim(tw_hash)[2])
options(warnings=-1)
for(a in 1:dim(tw_hash)[1]){
#pull the first element from the vector of treatments // take the first hash (tweet)
tw.temp<-tw_hash[a,]
# #subset the dataset for those treatments // keep only the tweets (#) rows (columns) where the hash (tweet) appear rep[a]=1
# temp<-subset(tw_hash, rep(tw_hash)==tw.temp)
#in this case the community data started at column 6, so the loop for co-occurrence has to start at that point
for(b in 1:(length(tw.temp)-1)){
#every species will be compared to every other species, so there has to be another loop that iterates down the rest of the columns
for(c in (b+1):(length(tw.temp))){
# for (d in 1:dim(temp)[1]) {
#
#   cooc_true <- sum(temp[d])
#   cooc_number <- 0
#
#   if(cooc_true >=1){
#
#       cooc_number <- cooc_number + 1
# }
if(tw.temp[b]+tw.temp[c]>1){
results[b,c]<-results[b,c]+1
results[c,b]<-results[c,b]+1
}
}
# #summing the abundances of species of the columns that will be compared
# species1.ab<-sum(temp[,b])
# species2.ab<-sum(temp[,c])
#
# #if the column is all 0's no co-occurrence will be performed
# if(species1.ab >1 & species2.ab >1){
#   # test<-cor.test(temp[,b],temp[,c],method="spearman",na.action=na.rm)
#   # rho<-test$estimate
#   # p.value<-test$p.value
#
# }
#
# if(species1.ab <=1 | species2.ab <= 1){
#   rho<-0
#   p.value<-1
# }
# trts = treatment-test
# new.row<-c(cooc_number,colnames(temp)[b],colnames(temp)[c]) # ,rho,p.value,species1.ab,species2.ab)
# results<-rbind(results,new.row)
#results[b,c]<-cooc_number
}
}
# plot network
library(igraph)
nodeNames <- levels(final_df$hashtag)
dimnames(results) <- list(nodeNames, nodeNames)
as_adj_mx <- as_adjacency_matrix(g, sparse = TRUE)
g <- graph_from_adjacency_matrix(results, mode = "undirected")
layout_nicely(g, dim = 2)
plot(g)
g <- graph_from_adjacency_matrix(results, mode = "undirected")
layout_nicely(g, dim = 3)
plot(g)
layout.auto(g)
plot(g)
g <- graph_from_adjacency_matrix(results, mode = "undirected")
layout.davidson.harel(g)
plot(g)
g <- graph_from_adjacency_matrix(results, mode = "undirected")
layout_randomly(g)
plot(g)
g <- graph_from_adjacency_matrix(results, mode = "undirected")
layout_with_graphopt(g)
plot(g)
g <- graph_from_adjacency_matrix(results, mode = "undirected")
layout_on_grid(g, dim = 3)
plot(g)
g <- graph_from_adjacency_matrix(results, mode = "undirected")
layout_on_grid(g, dim = 2)
plot(g)
g <- graph_from_adjacency_matrix(results, mode = "undirected")
layout_on_sphere(g)
plot(g)
View(results)
View(hash_df)
View(occ)
words_get_hashtags <- read.csv("~/Desktop/twitter_data_analysis/develop/Py/words_get_hashtags.csv")
View(words_get_hashtags)
words_get_hashtags_random <- read.csv("~/Desktop/twitter_data_analysis/develop/Py/words_get_hashtags_random.csv")
View(words_get_hashtags_random)
plot(words_get_hashtags)
plot(words_get_hashtags_random)
# set working directory
setwd("~/Desktop/twitter_data_analysis/scripts/R")
# query mongo and obtain a list
library(rmongodb)
mongo = mongo.create()
db.coll <- 'network.tracks'
cursor <- mongo.find(mongo, db.coll, query = '{}', fields = '{"_id":true,"entities.hashtags.text":true}')
coll <- mongo.cursor.to.list(cursor)
# clean
# build df |tweet_id|hashtag (long format: tweet_id is repeated for every hashtag contained)
tweet_id <- c()
hashtag<-c()
final_df <- data.frame(tweet_id, hashtag)
for(d in seq_along(coll)){
doc<-coll[[d]]
tweet_id <- c()
hashtag<-c()
for(i in seq_along(doc$entities$hashtags)){
tweet_id <- append(tweet_id, c(doc$`_id`))
hashtag <- append(hashtag, c(tolower(doc$entities$hashtags[i][[1]]$text)))
}
temp_df <- data.frame(tweet_id, hashtag)
final_df <- rbind(final_df, temp_df)
}
remove(list =  c("coll", "cursor", "d", "db.coll", "doc", "hashtag", "i", "mongo", "temp_df", "tweet_id"))
# buid occurrence matrix with unique tweet in rows and unique ashtag as column
hash_in_tweet <- as.matrix(xtabs(~hashtag + tweet_id, data=final_df))
#Transform Data into an Adjacency Matrix
# change it to a Boolean matrix
# hash_in_tweet[hash_in_tweet>=1] <- 1
# transform into a term-term adjacency matrix
ajx_mx_occ <- hash_in_tweet %*% t(hash_in_tweet)
# diagonal it's the total number an hashtag compare, considering it alone and wit others
# NORMALIZE
tot_occ_feat <- diag(ajx_mx_occ)
diag(ajx_mx_occ) <- 0
ajx_mx_prob <- ajx_mx_occ/tot_occ_feat
ajx_mx_prob[ajx_mx_prob>=1] <- 1
# inspect terms numbered 5 to 10
ajx_mx[5:10,5:10]
ajx_mx_prob[5:10,5:10]
row.names(subset(ajx_df,ecig > unname(quantile(ajx_df$ecig, c(.95))) & ecig < unname(quantile(ajx_df$ecig, c(1))), select = ecig)),
row.names(subset(ajx_df,ecig > unname(quantile(ajx_df$ecig, c(.95))) & ecig < unname(quantile(ajx_df$ecig, c(1))), select = ecig))
starting_list = c('ecig', 'vaping', 'vape', 'vaporizer', 'marijuana', 'sorrynotsorry', 'eliquid', 'ecigs', 'vapeporn', 'cannabis')
ajx_mx_occ <- hash_in_tweet %*% t(hash_in_tweet)
# diagonal it's the total number an hashtag compare, considering it alone and wit others
# NORMALIZE
tot_occ_feat <- diag(ajx_mx_occ)
diag(ajx_mx_occ) <- 0
ajx_mx_prob <- ajx_mx_occ/tot_occ_feat # NOTE: rows are divided, columns don't have mening animore
ajx_mx_prob[ajx_mx_prob>=1] <- 1
ajx_df <- as.data.frame(t(ajx_mx_prob))
################################
row.names(subset(ajx_df,ecig > unname(quantile(ajx_df$ecig, c(.95))) & ecig < unname(quantile(ajx_df$ecig, c(1))), select = ecig))
View(ajx_df)
ecig <- row.names(subset(ajx_df,ecig > unname(quantile(ajx_df$ecig, c(.95))) & ecig < unname(quantile(ajx_df$ecig, c(1))), select = ecig))
ecig
ecig <- row.names(subset(ajx_df,ecig > unname(quantile(ajx_df$ecig, c(.95))) & ecig < unname(quantile(ajx_df$ecig, c(1))), select = ecig))
vaping <- row.names(subset(ajx_df,vaping > unname(quantile(ajx_df$vaping, c(.95))) & vaping < unname(quantile(ajx_df$vaping, c(1))), select = vaping))
vape <- row.names(subset(ajx_df,vape > unname(quantile(ajx_df$vape, c(.95))) & vape < unname(quantile(ajx_df$vape, c(1))), select = vape))
vaporizer <- row.names(subset(ajx_df,vaporizer > unname(quantile(ajx_df$vaporizer, c(.95))) & vaporizer < unname(quantile(ajx_df$vaporizer, c(1))), select = vaporizer))
marijuana <- row.names(subset(ajx_df,marijuana > unname(quantile(ajx_df$marijuana, c(.95))) & marijuana < unname(quantile(ajx_df$marijuana, c(1))), select = marijuana))
sorrynotsorry <- row.names(subset(ajx_df,sorrynotsorry > unname(quantile(ajx_df$sorrynotsorry, c(.95))) & sorrynotsorry < unname(quantile(ajx_df$sorrynotsorry, c(1))), select = sorrynotsorry))
eliquid <- row.names(subset(ajx_df,eliquid > unname(quantile(ajx_df$eliquid, c(.95))) & eliquid < unname(quantile(ajx_df$eliquid, c(1))), select = eliquid))
ecigs <- row.names(subset(ajx_df,ecigs > unname(quantile(ajx_df$ecigs, c(.95))) & ecigs < unname(quantile(ajx_df$ecigs, c(1))), select = ecigs))
vapeporn <- row.names(subset(ajx_df,vapeporn > unname(quantile(ajx_df$vapeporn, c(.95))) & vapeporn < unname(quantile(ajx_df$vapeporn, c(1))), select = vapeporn))
cannabis <- row.names(subset(ajx_df,cannabis > unname(quantile(ajx_df$cannabis, c(.95))) & cannabis < unname(quantile(ajx_df$cannabis, c(1))), select = cannabis))
union(ecig, vaping, vape, marijuana, sorrynotsorry, eliquid, ecigs, vapeporn, cannabis)
un1 <- union(ecig, vaping)
un2 <- union(un1, vape)
un3 <- union(un2, vaporizer)
un4 <- union(un3, marijuana)
un5 <- union(un4, sorrynotsorry)
un6 <- union(un5, eliquid)
un7 <- union(un6, ecigs)
un8 <- union(un7, vapeporn)
un9 <- union(un8, cannabis)
levels(un9)
un9
unique(un9)
un1 <- unique(union(ecig, vaping))
un1 <- unique(union(ecig, vaping)))
un2 <- unique(union(un1, vape))
un3 <- unique(union(un2, vaporizer))
un4 <- unique(union(un3, marijuana))
un5 <- unique(union(un4, sorrynotsorry))
un6 <- unique(union(un5, eliquid))
un7 <- unique(union(un6, ecigs))
un8 <- unique(union(un7, vapeporn))
un9 <- unique(union(un8, cannabis))
un9
write.csv(un9)
write.csv(un9, file = "track1")
write.csv(un9, file = "track1.csv")
